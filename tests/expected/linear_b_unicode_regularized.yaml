# Test LB.R.1:
# Scenario: Test that blank spaces act as word separators within text in regularized scenarios (except for in specific scenarios, e.g. between a domesticated animal ideogram and a sex indicator).
# Requirements mapping:
    # LB.1-x: Tokenise each blank space (including Unicode '\u00a0') and use to distinguish individual words. Represent as is in both annotated and regularized output. 
        # This should occur in all but the specified exception scenarios (see LB.1-aâ€“d).
    # LB.1-e: If a blank space appears after a domesticated animal ideogram (i.e. EQU, SUS, OVIS, BOS or CAP) and before either a lowercase 'm' 'f' or  'x', then remove the space in both the annotated and regularized outputs.
    
    "CAP f 130 SUS 17 SUS f 41 BOS m 2 BOS f 4": "ğ‚ˆ 130 ğ‚ 17 ğ‚Š 41 ğ‚ 2 ğ‚Œ 4"
    "]SUS x 4 KO 80[" : "%ğ‚ 4 ğ€’ 80%"

# Test LB.R.2:
# Scenario: Test that hyphens act as sign separators within a word in regularized scenarios.
# Requirements mapping: 
    # LB.2: Tokenise each instance of '-' and use to recognise whole words in encoding, but do not represent this symbol in either the annotated or the regularized output.

    "a-ri-to-jo" : "ğ€€ğ€ªğ€µğ€"

# Test LB.R.3
# Scenario: Test that blank spaces after * and before and after '+' are removed in regularized scenarios.
# Requirements mapping:
    # LB.1-a: If a blank space appears after '*', then remove that space in both the annotated and regularized outputs.
    # LB.1-b: If a blank space appears before/after '+', then remove both those spaces in both the annotated and regularized outputs.

    "]qa-ra / re-me-to * 168 + SE 28" : "%ğ€£ğ€¨ ğ€©ğ€•ğ€µ ğ‚°+ğ€® 28"

# Test LB.R.4
# Scenario: Test that '--' is treated the same as as '-' in regularized scenarios.
# Requirements mapping:
    # LB.3: Tokenise each instance of '--' as '-' and use to recognise whole words in encoding, but do not represent this symbol in either the annotated or the regularized output.
    
    "a-ka--[ ]--jo-jo , me-no-[ da-pu2-ri-[-to-jo ]-po-ti-ni-ja ri *166+WE 22-[" : "ğ€€ğ€% %ğ€ğ€ ğ€•ğ€œ% ğ€…ğ†ğ€ª%ğ€µğ€ %ğ€¡ğ€´ğ€›ğ€Š ğ€ª ğ‚®+ğ€¸ 22%" # https://liber.cnr.it/tablet/view/124

# Test LB.R.5
# Scenario: Test that ']' and '[' are handled as wildcards in regularized scenarios, and that ',', '/' and '//' are not printed.
# Requirements mapping:
    # LB.4: Tokenise each instance of '/'. Represent this symbol as is in the annotated output, but do not include in the regularized output.
    # LB.5: Tokenise each instance of '//'. Represent this symbol as is in the annotated output, but do not include in the regularized output.
    # LB.6: Tokenise each instance of ','. Represent this symbol as is in the annotated output, but do not include in the regularized output.
    # LB.9: Tokenise each instance of '['. Represent this symbol as is in the annotated output, and represent as wildcard (i.e. '%') in regularized output.
    # LB.10: Tokenise each instance of ']'. Represent this symbol as is in the annotated output, and represent as wildcard (i.e. '%') in regularized output.

    "wo-de-wi-jo-jo , / me-no[ // ]ri-jo-de , ko-no , MA 3 ko-ri[ ]2 pa-de-i , ko-no MA 2 KO T 1[ [ ] pa-si-te-o-i , pa-sa-ja , ko-no , [ ] a-mi-ni-so-de , MA 2 KO T 4" : "ğ€ºğ€†ğ€¹ğ€ğ€ ğ€•ğ€œ% %ğ€ªğ€ğ€† ğ€’ğ€œ ğ€” 3 ğ€’ğ€ª% %2 ğ€ğ€†ğ€‚ ğ€’ğ€œ ğ€” 2 ğ€’ ğ„¼ 1% % % ğ€ğ€¯ğ€³ğ€ƒğ€‚ ğ€ğ€­ğ€Š ğ€’ğ€œ % % ğ€€ğ€–ğ€›ğ€°ğ€† ğ€” 2 ğ€’ ğ„¼ 4"

# Test LB.R.6
# Scenario: Test that ':' is not printed in regularized scenarios.
# Requirements mapping: 
    # LB.7: Tokenise each instance of ':'. Represent this symbol as is in the annotated output, but do not include in the regularized output.

    "a-ta-ti-nu  :  si-wa-[" : "ğ€€ğ€²ğ€´ğ€ ğ€¯ğ€·%"

# Test LB.R.7
# Scenario: Test that single quotation marks are not printed in regularized scenarios.
# Requirements mapping:
    # LB.8: Tokenise each instance of '''. Represent this symbol as is in the annotated output, but do not include in regularized output.

    "]wa VIR 1 MUL 2 'ko-wa 1' ko-wo 1": "%ğ€· ğ‚€ 1 ğ‚ 2 ğ€’ğ€· 1 ğ€’ğ€º 1"

# Test LB.R.8
# Scenario: Test that '\u0323' is not printed in regularized scenarios
# Requirements mapping:
    # LB.11: Ignore each instance of 'XÌ£' (or '\u0323') in tokenisation. Do not represent this symbol in either the annotated or the regularized output.

    "] ko-wo / m\u0323e\u0323[-zo] 1 ko-wo / me-wi-jo 2 [" : "% ğ€’ğ€º ğ€•%ğ€¿% 1 ğ€’ğ€º ğ€•ğ€¹ğ€ 2 %"

# Test LB.R.9
# Scenario: Test that '?' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.12: Tokenise each instance of '?'. Represent this symbol as is in the annotated output, but do not include in the regularized output.

    "i[-qi-ja?": "ğ€‚%ğ€¥ğ€Š"

# Test LB.R.10
# Scenario: Test that Scott brackets (i.e. 'âŸ¦' and 'âŸ§', or \u27e6 and \u27e7), and any characters they enclose, are not printed in regularized scenarios.
# Requirements mapping:
    # LB.13: Tokenise each instance of Scott brackets (i.e. 'âŸ¦' and 'âŸ§', or '\u27e6' and '\u27e7'). Represent these symbols as is in the annotated output. Do not include these symbols, or any other text that they contain, in the reguarised ouput.
 
    "po-*34-wi-do \u27e6TUN\u27e7 BIG[" : "ğ€¡ğ“ğ€¹ğ€ˆ ğƒŒ%"

# Test LB.R.11
# Scenario: Test that '<' and '>' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.14: Tokenise each instance of angle brackets (i.e. '<' and '>'). Represent this text as is in the annotated output. Do not include these symbols, or any other text that they contain, in the reguarised ouput.
    
    "] <OVIS:m> 69 OVIS:f 30 [ ]-e-ke-me-de , / tu-ni-ja , pa OVIS:m 1" : "% ğ‚‡ 69 ğ‚† 30 % %ğ€ğ€ğ€•ğ€† ğ€¶ğ€›ğ€Š ğ€ ğ‚‡ 1" # https://liber.cnr.it/tablet/view/3172?wl=12765

# Test LB.R.12
# Scenario: Test that half brackets (i.e. ' âŒ' and 'âŒŸ', or '\u2e24' and '\u2e25') are not printed in regularized scenarios.
# Requirements mapping:
    # LB.15: Tokenise each instance of lower half brackets (i.e. ' âŒ' and 'âŒŸ', or '\u2e24' and '\u2e25'). Represent these symbols as is in the annotated output. Do not include these symbols in the reguarised ouput.
    
    "du-to\u2e24 \u2e25 / r\u0323u\u0323-ki-to" : "ğ€‰ğ€µ ğ€¬ğ€‘ğ€µ"
    "e-ke-qe ]-o-na-to , ke-ke-me-naâŒ âŒŸko-to-na GRA qs ] vac.": "ğ€ğ€ğ€¤ %ğ€ƒğ€™ğ€µ ğ€ğ€ğ€•ğ€™ ğ€’ğ€µğ€™ ğ‚ % %"

# Test LB.R.13
# Scenario: Test that upper half brackets (i.e. 'âŒœ' and 'âŒ') are not printed in regularized scenarios.
# Requirements mapping
    # LB.16: Tokenise each instance of upper half brackets (i.e. ' âŒœ' and 'âŒ'). Represent these symbols as is in the annotated output. Do not include these symbols in the reguarised ouput.

    "]2 OLIV T 2 ] OLIV T 1 to]-ko-do-mo HORD[ ]Z 3 VIR 20[ pi-ri-e-te-re HORD[ ]Z 3 VIR 5 pa-te-ko-toâŒœ âŒHORD[ ]V 2 [ vacat qa-ra2-te , o[-pi-me-]ne[ ]OLIV 6 pa-ka , o-pi-me-ne , [ OLIV qs pa-te-ko-to , o-pi-me-ne[ ]HORD 1 [ pi-ri-e-te-si , o-pi-me-ne[ ]HORD 1 T 4[ to-ko-do-mo , o-pi-me-ne[ ]HORD 7[ ]5 vac." : "%2 ğ‚ ğ„¼ 2 % ğ‚ ğ„¼ 1 ğ€µ%ğ€’ğ€ˆğ€— ğ‚% %ğ„¿ 3 ğ‚€ 20% ğ€ ğ€ªğ€ğ€³ğ€© ğ‚% %ğ„¿ 3 ğ‚€ 5 ğ€ğ€³ğ€’ğ€µ ğ‚% %ğ„¾ 2 % ğ€£ğˆğ€³ ğ€ƒ%ğ€ ğ€•%ğ€š% %ğ‚ 6 ğ€ğ€ ğ€ƒğ€ ğ€•ğ€š % ğ‚ % ğ€ğ€³ğ€’ğ€µ ğ€ƒğ€ ğ€•ğ€š% %ğ‚ 1 % ğ€ ğ€ªğ€ğ€³ğ€¯ ğ€ƒğ€ ğ€•ğ€š% %ğ‚ 1 ğ„¼ 4% ğ€µğ€’ğ€ˆğ€— ğ€ƒğ€ ğ€•ğ€š% %ğ‚ 7% %5"

# Test LB.R.14
# Scenario: Test that '\u2082' is correctly handled as a subscript '2' in regularized scenarios
# Requirements mapping:
    # LB.17: Tokenise '\u2082' together with immediately preceding transliterated sign (as long as no hyphen '-' is between them). Confirm that it is treated correctly as a subscript '2', and expected Unicode sign is printed, as per mapping.

    "da-pu\u2082-ri-to-jo , / po-ti-ni-ja 'me-ri' * 209 VAS 1" : "ğ€…ğ†ğ€ªğ€µğ€ ğ€¡ğ€´ğ€›ğ€Š ğ€•ğ€ª ğƒ¨ 1"

# Test LB.R.15
# Scenario: Test that '\u2083' is correctly handled as a subscript '3' in regularized scenarios
# Requirements mapping:
    # LB.18: Tokenise '\u2083' together with immediately preceding transliterated sign (as long as no hyphen '-' is between them). Confirm that it is treated correctly as a subscript '3', and expected Unicode sign is printed, as per mapping.
    
    "pu-ri / a\u2083-zo-ro-qe , po-da-ko-qe BOS m ZE 1[" :  "ğ€¢ğ€ª ğğ€¿ğ€«ğ€¤ ğ€¡ğ€…ğ€’ğ€¤ ğ‚ ğ€½ 1%"

# Test LB.R.16
# Scenario: Test that 'mutila' is not printed in regularized scenarios.
# Requirements mapping:
    # LB 19: Tokenise each instance of 'mutila'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "] GRA[ qs mutila" : "% ğ‚% %"

# Test LB.R.17
# Scenario: Test that 'mut' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.20: Tokenise each instance of 'mut'. Represent this text as is in the annotated output, but do not include in the regularized output.
    
    "sup. mut. ]vacat [ ]A 5 A [ ]vest.[ inf. mut" : "% % %ğ€€ 5 ğ€€ % %%%"

# Test LB.R.18
# Scenario: Test that 'sup. mut.', 'inf. mut.' and 'vac.' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.21: Tokenise each instance of 'sup.' and 'mut.'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.22: Tokenise each instance of 'inf.' and 'mut.'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.23: Tokenise each instance of 'vac.'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "sup. mut. ] wo[ ] vac. [ inf. mut." : "% ğ€º% % %"

# Test LB.R.19
# Scenario: Test that 'vacat' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.24: Tokenise each instance of 'vacat'. Represent this text as is in the annotated output, but do not include in the regularized output.
    
    "] vacat [" : ""
    "] vacat v. ] 1" : "% % 1"

# Test LB.R.20
# Scenario: Test that 'vest.' is handled as a wildcard in regularized scenarios, and that Unicode '\u00a0' is treated as a blank space.
# Requirements mapping:
    # LB.1-x: Tokenise each blank space (including Unicode '\u00a0') and use to distinguish individual words. Represent as is in both annotated and regularized output. 
        # This should occur in all but the specified exception scenarios (see LB.1-aâ€“d).
    # LB.25: Tokenise each instance of 'vest.'. Represent this text as is in the annotated output, and represent as wildcard (i.e. '%') in regularized output.
    
    "] vest ., / su-ri-mo , u-ta-jo-jo , o OVIS m 85[\u00a0] vac ." : "% % ğ€±ğ€ªğ€— ğ€„ğ€²ğ€ğ€ ğ€ƒ ğ‚‡ 85% %"

# Test LB.R.21
# Scenario: Test that 'vestigia' is handled as a wildcard in regularized scenarios.
# Requirements mapping:
    # LB.26: Tokenise each instance of 'vestigia'. Represent this text as is in the annotated output, and represent as wildcard (i.e. '%') in regularized output.

    'pa-ro , we-u-da-ne-we re-u-ko , a-ko-ro-we-e BOS+SI 2 re[-u-]ko , ma-ra-pi , pe-ko , a-ko-ro-we BOS+SI 1 OVIS:m? ]3 CAP:m 3 WE 3 CAP:m 3 ]vestigia[ ]2 [ ]BOS:x 3 âŸ¦ âŸ§ ] vest. [ ] vest. [ re-u-ko[ ]ma-ra[-pi ]pe-ko , a-ko-ro-we[ OVIS:m 1 CAP:m 1 WE[ ] SUS:x[ ] vacat [ inf. mut.' : 'ğ€ğ€« ğ€¸ğ€„ğ€…ğ€šğ€¸ ğ€©ğ€„ğ€’ ğ€€ğ€’ğ€«ğ€¸ğ€ ğ€˜+ğ€¯ 2 ğ€©%ğ€„%ğ€’ ğ€”ğ€¨ğ€  ğ€Ÿğ€’ ğ€€ğ€’ğ€«ğ€¸ ğ€˜+ğ€¯ 1 ğ‚‡ %3 ğ‚‰ 3 ğ€¸ 3 ğ‚‰ 3 %%% %2 % %ğ€˜ 3 % % % % % % ğ€©ğ€„ğ€’% %ğ€”ğ€¨%ğ€  %ğ€Ÿğ€’ ğ€€ğ€’ğ€«ğ€¸% ğ‚‡ 1 ğ‚‰ 1 ğ€¸% % ğ‚% % %'

# Test LB.R.22
# Scenario: Test that 'vestigia?' is handled as a wildcard in regularized scenarios.
# Requirements mapping:
    # LB.27: Tokenise each instance of 'vestigia?'. Represent this text as is in the annotated output, and represent as wildcard (i.e. '%') in regularized output.

    "su-ma-no / ti-ri-to [ vestigia? ] vacat" : "ğ€±ğ€”ğ€œ ğ€´ğ€ªğ€µ % % %"

# Test LB.R.23
# Scenario: Test that 'qs' (i.e. 'quantum sufficit') is converted to a wildcard in regularized scenarios.
# Requirements mapping:
    # LB.28: Tokenise each instance of 'qs'. Represent this text as is in the annotated output, but represent as wildcard (i.e. '%') in regularized output.
    
    "]-ke-ke-me-na-[ , ko-]-to-na GRA qs ] vac." : "%ğ€ğ€ğ€•ğ€™% ğ€’%ğ€µğ€™ ğ‚ % %"

# Test LB.R.24
# Scenario: Test that 'fragmentum separatum', 'Î±', 'Î²', 'Î³' and 'Î´'  are not printed in regularized scenarios.
# Requirements mapping:
    # LB.29: Tokenise each instance of 'fragmentum separatum'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.53: Tokenise each instance of 'Î±'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.54: Tokenise each instance of 'Î²'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.55: Tokenise each instance of 'Î³'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.56: Tokenise each instance of 'Î´'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "da-we-u[-pi ]a-ko[ da-we-u-pi , a[ da-we-u-pi , ka[ da-we-u-pi , e-[ a3-zo-wo[ da-we[-u-]pi âŒ âŒŸwo[ da-we-u-pi , e-ke[ da-we-u[-pi a-re[ a-zo[ inf. mut. fragmentum separatum Î± sup. mut. ]  OVIS:f X 15 [ fragmentum separatum Î² ] , ka[ fragmentum separatum Î³ sup. mut. ]no-wo[ fragmentum separatum Î´ sup. mut. ]ma-jo-wo-[ inf. mut." : "ğ€…ğ€¸ğ€„%ğ€  %ğ€€ğ€’% ğ€…ğ€¸ğ€„ğ€  ğ€€% ğ€…ğ€¸ğ€„ğ€  ğ€% ğ€…ğ€¸ğ€„ğ€  ğ€% ğğ€¿ğ€º% ğ€…ğ€¸%ğ€„%ğ€  ğ€º% ğ€…ğ€¸ğ€„ğ€  ğ€ğ€% ğ€…ğ€¸ğ€„%ğ€  ğ€€ğ€©% ğ€€ğ€¿% % ğ‚† 15 % % ğ€% %ğ€œğ€º% %ğ€”ğ€ğ€º%"

# Test LB.R.25
# Scenario: Test that 'fragmentum A' and 'fragmentum B' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.30: Tokenise each instance of 'fragmentum A'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.31: Tokenise each instance of 'fragmentum B'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "fragmentum A fragmentum B vacat [ sup. mut. e-me-si-jo-jo-[ ] 3-[ pa-na-so GRA 100-[ ]-vac.-[ ta-ra-qo GRA [ inf. mut. ta-u-pa-du-we GRA-[ a-ro-ja-[ pu-na-so-[ inf. mut." : "% ğ€ğ€•ğ€¯ğ€ğ€% % 3% ğ€ğ€™ğ€° ğ‚ 100% %% ğ€²ğ€¨ğ€¦ ğ‚ % ğ€²ğ€„ğ€ğ€‰ğ€¸ ğ‚% ğ€€ğ€«ğ€Š% ğ€¢ğ€™ğ€°%"

# Test LB.R.26
# Scenario: Test that 'fragmentum C' and 'fragmentum D' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.32: Tokenise each instance of 'fragmentum C'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.33: Tokenise each instance of 'fragmentum D'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "fragmentum A fragmentum B sup. mut. sup. mut. ]-na 1 i-[ ]so-i-[ ko-wa   1[ ]ku-mi-[â€¢]-du 1[ inf. mut. vac. [ vac. [ fragmentum C fragmentum D sup. mut. sup. mut. ]di-mi[ ]vac. ]*56-za[ ]vac. inf. mut. inf. mut." : "%ğ€™ 1 ğ€‚% %ğ€°ğ€‚% ğ€’ğ€· 1% %ğ€“ğ€–%ğ€‰ 1% % % %ğ€‡ğ€–% % %ğ–ğ€¼% %"

# Test LB.R.27
# Scenario: Test that 'deest' (or its abbreviation, 'dt') is not printed in regularized scenarios.
# Requirements mapping:
    # LB.34: Tokenise each instance of 'deest' or 'dt'. Represent this text as is in the annotated output, but do not include in the regularized output.
    
    "sup. mut. ]-deest-[ inf. mut." : ""
    "]GRA 37 T 6[ ] vac. [ ]âŒdeestâŒŸ vac.  âŒdtâŒŸ [" : "%ğ‚ 37 ğ„¼ 6% % % % %"

# Test LB.R.28
# Scenario: Test that 'prior pars sine regulis' is not printed in regularized scenarios, and that any 'â€¢' are converted to single wildcards (i.e. '%').
# Requirements mapping
    # LB.35: Tokenise each instance of 'prior pars sine regulis'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.57: Tokenise each instance of 'â€¢'. Represent this text as is in the annotated output, and represent as wildcard (i.e. '%') in regularized output.

    "]-ke-ra2-u-na , e-ra[ ]â€¢ po-se-da-o-neâŒ âŒŸre-ko-no 6 [ *146 18[ ] LANA 2 M 2[ AÂ±REÂ±PA V 4[ ]â€¢ 1 OVIS:m 1 OVIS:f 1 CAP:f[ qs SUS+KA 2 SUS:f 4[ ]â€¢ 1 FAR T 1 V [ qs VIN 5 TELA [ ] 1 TELA+PA 1 vac. vac. vac. [ ]3[ ]-we-e-a2[ inf. mut. v. prior pars sine regulis ]e-ke-me-de , do[ ]du-ru-wo-qo deest vac. vac. vac. vac. vac. vac." : "%ğ€ğˆğ€„ğ€™ ğ€ğ€¨% %% ğ€¡ğ€®ğ€…ğ€ƒğ€š ğ€©ğ€’ğ€œ 6 % ğ‚ 18% % ğ‚ 2 ğ„¸ 2% ğ‚˜ ğ„¾ 4% %% 1 ğ‚‡ 1 ğ‚† 1 ğ‚ˆ% % ğ‚+ğ€ 2 ğ‚Š 4% %% 1 ğ€ ğ„¼ 1 ğ„¾ % % ğ‚– 5 ğ‚§ % % 1 ğ‚§+ğ€ 1 % %3% %ğ€¸ğ€ğ€% %ğ€ğ€ğ€•ğ€† ğ€ˆ% %ğ€‰ğ€¬ğ€ºğ€¦"

# Test LB.R.29
# Scenario: Test that 'reliqua pars sine regulis' is not printed in regularized scenarios.
# Requirements mapping
    # LB.36: Tokenise each instance of 'reliqua pars sine regulis'. Represent this text as is in the annotated output, but do not include in the regularized output.
    
    "sup. mut. ]-vest.-[ ]-na-ro GRA 5 ]--do-we-i , ma-so-qe GRA 8 ] vac. ] GRA 402 OLIV+A 52 reliqua pars sine regulis" : "%%% %ğ€™ğ€« ğ‚ 5 %ğ€ˆğ€¸ğ€‚ ğ€”ğ€°ğ€¤ ğ‚ 8 % % ğ‚ 402 ğ‚+ğ€€ 52"

# Test LB.R.30
# Scenario: Test that 'angustum' and '[â€¢~]' are not printed in regularized scenarios.
# Requirements mapping
    # LB.37: Tokenise each instance of 'angustum'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.59: Tokenise each instance of '[â€¢~]'. Represent this text as is in the annotated output, and represent a single wildcard (i.e. '%') in regularized output.
    
    "a[ ]te VIR[ 1 ]ke-ro-si-ja , a[ ] VIR 1 ke-ro-]si-ja , [â€¢~]me-ka-[â€¢] VIR 1 a-[ ke-ro-]si-ja , o-pa-[ ]vac.[ VIR 1 vac.[ ] vac. vac. [ ] vac. v. ta-we-si-jo-jo , ke-ro-si-ja , te-wa[ VIR 1 ta-]we-si-jo-jo , ke-ro-si-ja , tu-ru-we-u VIR 1 ] angustum ta-]we-si-jo-jo , ke-ro-si VIR 20 a-pi-qo-ta-o , ke-ro-si-ja VIR 17 a-pi-o-to , ke-ro-si-ja VIR [1]8âŒŸ o-to-wo[-o ke-]ro-si-ja VIR [1]4 angustum [ ] [ ] ka-ma-e[-we] VIR 10" : "ğ€€% %ğ€³ ğ‚€% 1 %ğ€ğ€«ğ€¯ğ€Š ğ€€% % ğ‚€ 1 ğ€ğ€«%ğ€¯ğ€Š ğ€•ğ€% ğ‚€ 1 ğ€€% ğ€ğ€«%ğ€¯ğ€Š ğ€ƒğ€% %% ğ‚€ 1 % % % % ğ€²ğ€¸ğ€¯ğ€ğ€ ğ€ğ€«ğ€¯ğ€Š ğ€³ğ€·% ğ‚€ 1 ğ€²%ğ€¸ğ€¯ğ€ğ€ ğ€ğ€«ğ€¯ğ€Š ğ€¶ğ€¬ğ€¸ğ€„ ğ‚€ 1 % ğ€²%ğ€¸ğ€¯ğ€ğ€ ğ€ğ€«ğ€¯ ğ‚€ 20 ğ€€ğ€ ğ€¦ğ€²ğ€ƒ ğ€ğ€«ğ€¯ğ€Š ğ‚€ 17 ğ€€ğ€ ğ€ƒğ€µ ğ€ğ€«ğ€¯ğ€Š ğ‚€ %1%8 ğ€ƒğ€µğ€º%ğ€ƒ ğ€%ğ€«ğ€¯ğ€Š ğ‚€ %1%4 % % % % ğ€ğ€”ğ€%ğ€¸% ğ‚€ 10"

# Test LB.R.31
# Scenario: Test that 'graffito' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.38: Tokenise each instance of 'graffito'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "]e-ke , e-u-da-i-ta OVIS:f 39[ ]ki-u-ro , / su-ki-ri-ta-pi o ki OVIS 15 [ v. graffito lat. inf." : "%ğ€ğ€ ğ€ğ€„ğ€…ğ€‚ğ€² ğ‚† 39% %ğ€‘ğ€„ğ€« ğ€±ğ€‘ğ€ªğ€²ğ€  ğ€ƒ ğ€‘ ğ€¥ 15 %"

# Test LB.R.32
# Scenario: Test that 'Graffito' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.39: Tokenise each instance of 'Graffito'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "] Graffito [": ""

# Test LB.R.33
# Scenario: Test that 'r.' and 'r.p' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.40: Tokenise each instance of 'r.' or 'r.p'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "lat. sup. ] KE [ r. ]VIN 1 S 2[ ]1 ko-ta V[" : "% ğ€ % %ğ‚– 1 ğ„½ 2% %1 ğ€’ğ€² ğ„¾%"
    "v. ]i-je-re-ja TELA+TE[ qs ka-]ra-wi-po-ro TELA+TE[ qs lat. dex. ] âŸ¦WE 30âŸ§ r.p vacat vestigia po-se-da-o-ne [ po-de-da-o-ne" : "%ğ€‚ğ€‹ğ€©ğ€Š ğ‚§+ğ€³% % ğ€%ğ€¨ğ€¹ğ€¡ğ€« ğ‚§+ğ€³% % % % ğ€¡ğ€®ğ€…ğ€ƒğ€š % ğ€¡ğ€†ğ€…ğ€ƒğ€š"

# Test LB.R.34
# Scenario: Test that 'v.' and 'v.p' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.41: Tokenise each instance of 'v.' or 'v.p'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "to-re : : : : [ v. di-we si-po-ro ti-mi-to-qo [" : "ğ€µğ€© % ğ€‡ğ€¸ ğ€¯ğ€¡ğ€« ğ€´ğ€–ğ€µğ€¦ %"
    "ARM 1 me-zo-a2 O 22 me-u-jo-a2 O 12 KO O 4 PA 2 v.p to-mi-re-[ ]wa-[ ]-re-[ ]e-ko-si o-to-pe-da-ko-we-de-[â€¢]-ke[" : "ğ‚« 1 ğ€•ğ€¿ğ€ ğ€ƒ 22 ğ€•ğ€„ğ€ğ€ ğ€ƒ 12 ğ€’ ğ€ƒ 4 ğ€ 2 ğ€µğ€–ğ€©% %ğ€·% %ğ€©% %ğ€ğ€’ğ€¯ ğ€ƒğ€µğ€Ÿğ€…ğ€’ğ€¸ğ€†%ğ€%"

# Test LB.R.35
# Scenario: Test that 'v.â†“' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.42: Abbreviated form of verso, indicates the reverse side of the tablet, when inscribed.Â Arrow indicates direction that record is rotated to reach verso.
    
    "qe-te-o TELA;2-[ po-po TELA;2 4 [ v.â†“ âŸ¦a-mi-si-ja TELA;1 12âŸ§ [" : "ğ€¤ğ€³ğ€ƒ ğ‚§Â²% ğ€¡ğ€¡ ğ‚§Â² 4 % %"

# Test LB.R.36
# Scenario: Test that 'v.â†’' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.43: Tokenise each instance of 'v.â†’'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "ne-wo , za-we-[ v.â†’ ] a-ro-we a-nu-to" : "ğ€šğ€º ğ€¼ğ€¸% % ğ€€ğ€«ğ€¸ ğ€€ğ€ğ€µ"

# Test LB.R.37
# Scenario: Test that blank spaces are removed before the full stop for 'l .' and 's .', and that the resulting 'l.' and 's.' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.1-c: If a space appears before a '.'  in an annotation (e.g. 'lat .'), then remove that space in both the annotated and regularized outputs.
    # LB.44: Tokenise each instance of 'l.'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.46: Tokenise each instance of 's.'. Represent this text as is in the annotated output, but do not include in the regularized output.
 
    "l . s . ]\u27e6 vest . \u27e7[": ""

# Test LB.R.38
# Scenario: Test that blank spaces are removed before the full stop for 'l .' and 'i .', and that the resulting 'l.' and 'i.' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.1-c: If a space appears before a '.'  in an annotation (e.g. 'lat .'), then remove that space in both the annotated and regularized outputs.
    # LB.44: Tokenise each instance of 'l.'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.48: Tokenise each instance of 'i.'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "l . i . LANA 250[": "ğ‚ 250%"

# Test LB.R.39
# Scenario: Test that 'lat.' and 'inf.' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.45: Tokenise each instance of 'lat.'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.49: Tokenise each instance of 'inf.'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "l\u0323a\u0323t\u0323 . i\u0323n\u0323f\u0323 .": ""

# Test LB.R.40
# Scenario: Test that 'lat.' and 'sup.' are not printed in regularized scenarios.
# Requirements mapping:
    # LB.45: Tokenise each instance of 'lat.'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # LB.47: Tokenise each instance of 'sup.'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "] TELA;4+âŸ¦ZOâŸ§ 1 [ ]LANA M 1[ v.â†“ ]-a ra[ lat. sup.]-so-ma [" : "% ğ‚§â´+ 1 % %ğ‚ ğ„¸ 1% %ğ€€ ğ€¨% %ğ€°ğ€” %"

# Test LB.R.41
# Scenario: Test that 'dex.' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.50: Tokenise each instance of 'dex.'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "wo-di-je-ja , de-mi-ni-ja 1 ma-no , a-re-ka-sa-da-ra-ka 2 ri-su-ra , qo-ta-qe 2 e-ri-tu-pi-na , te-o-do-ra-'qe' 2 o-to-wo-wi-je tu-ka-te-qe 2 a-ne-a2 , tu-ka-te-qe 2 pi-ro-wo-na ki-ra-qe 2 pu-ka-ro ke-ti-de-qe 2 ]-ri-mo-qe 2 ]ma-ta-qe 2 ]*82 1 ]-qe 2 ] vac. inf. mut. lat. dex. ] , i-ri-[â€¢ ]1 ke-ra-so , ki-ra-qe 2" : "ğ€ºğ€‡ğ€‹ğ€Š ğ€†ğ€–ğ€›ğ€Š 1 ğ€”ğ€œ ğ€€ğ€©ğ€ğ€­ğ€…ğ€¨ğ€ 2 ğ€ªğ€±ğ€¨ ğ€¦ğ€²ğ€¤ 2 ğ€ğ€ªğ€¶ğ€ ğ€™ ğ€³ğ€ƒğ€ˆğ€¨ğ€¤ 2 ğ€ƒğ€µğ€ºğ€¹ğ€‹ ğ€¶ğ€ğ€³ğ€¤ 2 ğ€€ğ€šğ€ ğ€¶ğ€ğ€³ğ€¤ 2 ğ€ ğ€«ğ€ºğ€™ ğ€‘ğ€¨ğ€¤ 2 ğ€¢ğ€ğ€« ğ€ğ€´ğ€†ğ€¤ 2 %ğ€ªğ€—ğ€¤ 2 %ğ€”ğ€²ğ€¤ 2 %ğš 1 %ğ€¤ 2 % % ğ€‚ğ€ª%% %1 ğ€ğ€¨ğ€° ğ€‘ğ€¨ğ€¤ 2"

# Test LB.R.42
# Scenario: Test that 'sigillum' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.51: Tokenise each instance of 'sigillum'. Represent this text as is in the annotated output, but do not include in the regularized output.
    
    "Î± sigillum Î² qe-ti-ja Î³ vac." : "ğ€¤ğ€´ğ€Š"

# Test LB.R.43
# Scenario: Test that 'supra sigillum' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.52: Tokenise each instance of 'supra sigillum'. Represent this text as is in the annotated output, but do not include in the regularized output.
    # If a notation about the seal type is also included (e.g. '=A', indicating that the seal is of type 'A', according to the publication of the Thebes sealings (Olivier et al. 1982), then also represent this in the annotated output, but do not include in the regularized output.
    
    "Î± JAC supra sigillum Î² o-pa Î³ pa-ta-ja" : "ğƒ˜ ğ€ƒğ€ ğ€ğ€²ğ€Š"
    "Î± OVIS:m supra sigillum=R Î² vac. Î³ vac." : "ğ‚‡"
    "Î± CAP:m supra sigillum=Z=1 Î² vac. Î³ ]vac." : "ğ‚‰ %"

# Test LB.R.44
# Scenario: Test that '[â€¢]' (or '[\u2022]') is converted to a single wildcard (i.e. '%') in regularized scenarios.
# Requirements mapping:
    # LB.58: Tokenise each instance of '[â€¢]' or '[\u2022]''. Represent this symbol as is in the annotated output, and represent as a single wildcard (i.e. '%') in regularized output.

    "]po-[\u2022] , / [ OVIS m ] 40 o OVIS m 20" : "%ğ€¡% % ğ‚‡ % 40 ğ€ƒ ğ‚‡ 20"

# Test LB.R.45
# Scenario: Test that 'â€¢~â€¢' is converted to two wildcards, i.e. '%%', in regularized scenarios.
# Requirements mapping:
    # LB.60: Tokenise each instance of 'â€¢~â€¢'. Represent this text as is in the annotated output, and represent as two wildcards (i.e. '%%') in regularized output.

    "ma-mi-di-zo / pi-ri-to-jo OVIS:f 40[ [â€¢~â€¢]-ro ,  da-nu-wo OVIS:f 100[ po-ri-wo , / su-ki-ri-ta-jo , wo-we-u CAP:m 180 ja-ru , / pa-ta-ti-jo , do-e-ro , CAP:f 230 a-du-po-to , / qi-ko-we-e , do-e-ro , CAP:f 90 qa-di-ja , / po-ku-te-ro , da-mo , 'do-e-ro' CAP:f 70 da-[â€¢~â€¢ / ]po-ku-ta CAP:f 130 ra-wa-ni , / po-ku-ta , ra-ri-di-jo OVIS:m 190 o-mi-ri-so , / ta-so , do-e-ro OVIS:m 50 [â€¢~â€¢]-so / a-pi-me-de-o , po-ku-ta 'ra-ri-di-jo' OVIS:f 140 ku-jo-[ / ]ta-so , // do-e-ro OVIS:f 100 a-*56-da-ro / ka-ta-mi-jo , do-e-ro OVIS:x[ a-ra-ko , / ra-ri-di-jo , do-e-ro OVIS:m 100[ vac. vac. vac." : "ğ€”ğ€–ğ€‡ğ€¿ ğ€ ğ€ªğ€µğ€ ğ‚† 40% %%ğ€« ğ€…ğ€ğ€º ğ‚† 100% ğ€¡ğ€ªğ€º ğ€±ğ€‘ğ€ªğ€²ğ€ ğ€ºğ€¸ğ€„ ğ‚‰ 180 ğ€Šğ€¬ ğ€ğ€²ğ€´ğ€ ğ€ˆğ€ğ€« ğ‚ˆ 230 ğ€€ğ€‰ğ€¡ğ€µ ğ€¥ğ€’ğ€¸ğ€ ğ€ˆğ€ğ€« ğ‚ˆ 90 ğ€£ğ€‡ğ€Š ğ€¡ğ€“ğ€³ğ€« ğ€…ğ€— ğ€ˆğ€ğ€« ğ‚ˆ 70 ğ€…%% %ğ€¡ğ€“ğ€² ğ‚ˆ 130 ğ€¨ğ€·ğ€› ğ€¡ğ€“ğ€² ğ€¨ğ€ªğ€‡ğ€ ğ‚‡ 190 ğ€ƒğ€–ğ€ªğ€° ğ€²ğ€° ğ€ˆğ€ğ€« ğ‚‡ 50 %%ğ€° ğ€€ğ€ ğ€•ğ€†ğ€ƒ ğ€¡ğ€“ğ€² ğ€¨ğ€ªğ€‡ğ€ ğ‚† 140 ğ€“ğ€% %ğ€²ğ€° ğ€ˆğ€ğ€« ğ‚† 100 ğ€€ğ–ğ€…ğ€« ğ€ğ€²ğ€–ğ€ ğ€ˆğ€ğ€« ğ€¥% ğ€€ğ€¨ğ€’ ğ€¨ğ€ªğ€‡ğ€ ğ€ˆğ€ğ€« ğ‚‡ 100%"

# Test LB.R.46
# Scenario: Test that 'â—' is not printed in regularized scenarios, and that [â€¢~â€¢] is converted to two wildcards, i.e. '%%'.
# Requirements mapping:
    # LB.61: Tokenise each instance of '[â€¢~â€¢]'. Represent this text as is in the annotated output, and represent as two wildcards (i.e. '%%') in regularized output.
    # LB.66: Tokenise each instance of 'â—'. Represent this text as is in the annotated output, but do not include in the regularized output.
    
    "[â€¢~â€¢] [ wi-tu-ri-jo , / a-mo-te-re [" : "%% % ğ€¹ğ€¶ğ€ªğ€ ğ€€ğ€—ğ€³ğ€© %" # https://liber.cnr.it/tablet/view/4230?wl=23478,23481,23485
    "sup. mut. ]vest.[ di-pa AES *214VAS+DI 30[ qe-ro2 'AES' *255 â— 16 ku-ru-su-*56 â— *207VAS 1 pi-ri-je â— ZE 1 [â€¢~â€¢] 'me-no-no[' inf. mut." : "%%% ğ€‡ğ€ ğ‚š ğƒ­+ğ€‡ 30% ğ€¤ğŠ ğ‚š ğƒ™ 16 ğ€“ğ€¬ğ€±ğ– ğƒ¦ 1 ğ€ ğ€ªğ€‹ ğ€½ 1 %% ğ€•ğ€œğ€œ%"

# Test LB.R.47
# Scenario: Test that 'â€¢~â€¢~' is converted to two wildcards, i.e. '%%', in regularized scenarios.
# Requirements mapping:
    # LB.62: Tokenise each instance of 'â€¢~â€¢~'. Represent this text as is in the annotated output, and represent as two wildcards (i.e. '%%') in regularized output.

    # ADD TC

# Test LB.R.48
# Scenario: Test that '[â€¢~â€¢~]' is converted to two wildcards, i.e. '%%', in regularized scenarios.
# Requirements mapping:
    # LB.63: Tokenise each instance of '[â€¢~â€¢~]'. Represent this text as is in the annotated output, and represent as two wildcards (i.e. '%%') in regularized output.

    "][â€¢~â€¢~]*34-so , 'da-*22-to' OVIS:m 50 [ ]do-ti , ti-ri-to OVIS:m 50 [" : "%%%ğ“ğ€° ğ€…ğ’ğ€µ ğ‚‡ 50 % %ğ€ˆğ€´ ğ€´ğ€ªğ€µ ğ‚‡ 50 %"

# Test LB.R.49
# Scenario: Test that 'â€¢~â€¢~â€¢' is converted to three wildcards, i.e. '%%%', in regularized scenarios.
# Requirements mapping:
    # LB.64: Tokenise each instance of 'â€¢~â€¢~â€¢'. Represent this text as is in the annotated output, and represent as three wildcards (i.e. '%%%') in regularized output.

    # ADD TC

# Test LB.R.50
# Scenario: Test that '[â€¢~â€¢~â€¢]' is converted to three wildcards, i.e. '%%%', in regularized scenarios.
# Requirements mapping:
    # LB.65: Tokenise each instance of '[â€¢~â€¢~â€¢]'. Represent this text as is in the annotated output, and represent as three wildcards (i.e. '%%%') in regularized output.

    "] vest. [ [â€¢~â€¢~â€¢]-ra-de / ne-wo-jo OLE 4[ ] vac. [": "% % % %%%ğ€¨ğ€† ğ€šğ€ºğ€ ğ‚• 4% % %"

# Test LB.U.51
# Scenario: Test that 'â€¢~â€¢~â€¢~â€¢' is converted to four wildcards, i.e. '%%%%', in regularized scenarios.
# Requirements mapping:
    # LB.66: Tokenise each instance of 'â€¢~â€¢~â€¢~â€¢'. Represent this text as is in the annotated output, and represent as four wildcards (i.e. '%%%%') in regularized output.

    "au-ke-i-ja-te-we , ka-tu-re-wi-ja-i di-pte-ra 4 [ â€¢~â€¢~â€¢~â€¢ ]di-pte-ra 2 au-ke-i-ja-te-we , o-ka , di-pte-ra[ au-ke-i-ja-te-we o-pi-de-so-moâŒ âŒŸka-tu-ro2 , di-pte-ra 4 ka-ne-jaâŒ âŒŸwo-ro-ma-ta 4 me-ti-ja-no , to-pa , ru-de-a2 , di-pte-ra 1 a-re-se-si , e-ru-ta-ra , di-pte-ra 3 wo-di-je-ja , pe-di-ra 2 we-e-wi-ja , di-pte-ra , 10 wi-ri-no , we-ru-ma-ta , ti-ri-si , ze-u-ke-si 1 wi-ri-no , pe-di-ro , e-ma-ta 4 e-ra-pe-ja , e-pi-u-ru-te-we , E 2 a-pe-i-ja , u-po , ka-ro , we-[ ]-ja 1 u-po , we-e-wi-ja , e-ra-pe-ja E 1 mu-te-we , we-re-ne-ja , ku[ ]pe-re 1 mu-te-we , di-pte-ra , a3-za , pe-di-ro-i 1 vac. vac. vac." : "ğ‚ğ€ğ€‚ğ€Šğ€³ğ€¸ ğ€ğ€¶ğ€©ğ€¹ğ€Šğ€‚ ğ€‡ğ‡ğ€¨ 4 % %%%% %ğ€‡ğ‡ğ€¨ 2 ğ‚ğ€ğ€‚ğ€Šğ€³ğ€¸ ğ€ƒğ€ ğ€‡ğ‡ğ€¨% ğ‚ğ€ğ€‚ğ€Šğ€³ğ€¸ ğ€ƒğ€ ğ€†ğ€°ğ€— ğ€ğ€¶ğŠ ğ€‡ğ‡ğ€¨ 4 ğ€ğ€šğ€Š ğ€ºğ€«ğ€”ğ€² 4 ğ€•ğ€´ğ€Šğ€œ ğ€µğ€ ğ€¬ğ€†ğ€ ğ€‡ğ‡ğ€¨ 1 ğ€€ğ€©ğ€®ğ€¯ ğ€ğ€¬ğ€²ğ€¨ ğ€‡ğ‡ğ€¨ 3 ğ€ºğ€‡ğ€‹ğ€Š ğ€Ÿğ€‡ğ€¨ 2 ğ€¸ğ€ğ€¹ğ€Š ğ€‡ğ‡ğ€¨ 10 ğ€¹ğ€ªğ€œ ğ€¸ğ€¬ğ€”ğ€² ğ€´ğ€ªğ€¯ ğ€½ğ€„ğ€ğ€¯ 1 ğ€¹ğ€ªğ€œ ğ€Ÿğ€‡ğ€« ğ€ğ€”ğ€² 4 ğ€ğ€¨ğ€Ÿğ€Š ğ€ğ€ ğ€„ğ€¬ğ€³ğ€¸ ğ€ 2 ğ€€ğ€Ÿğ€‚ğ€Š ğ€„ğ€¡ ğ€ğ€« ğ€¸% %ğ€Š 1 ğ€„ğ€¡ ğ€¸ğ€ğ€¹ğ€Š ğ€ğ€¨ğ€Ÿğ€Š ğ€ 1 ğ€˜ğ€³ğ€¸ ğ€¸ğ€©ğ€šğ€Š ğ€“% %ğ€Ÿğ€© 1 ğ€˜ğ€³ğ€¸ ğ€‡ğ‡ğ€¨ ğğ€¼ ğ€Ÿğ€‡ğ€«ğ€‚ 1"

# Test LB.U.52
# Scenario: Test that '[â€¢~â€¢~â€¢~â€¢]' is converted to four wildcards, i.e. '%%%%', in regularized scenarios.
# Requirements mapping:
    # LB.67: Tokenise each instance of '[â€¢~â€¢~â€¢~â€¢]'. Represent this text as is in the annotated output, and represent as four wildcards (i.e. '%%%%') in regularized output.

    "sup. mut. ] i-[-jo ]-wo , a-[ ] wa-du-na , [â€¢~â€¢~â€¢~â€¢] ]--to , e-[ ] vac. ]-sa-ka-ri-jo , [ ] vac. i-jo i-jo [o-]-pi / di-zo , pi-ma-na-ro , zo-wi-jo 1 a-tu-qo-te-ra-to 1-[ i-jo o-pi / ri-zo , pi-ma-na-ro pi-ro-i-ta 1 o-pi / pa-ka , di-wa-jo 1 ]-pi / o-na-se-u 1 ri--[ ]-wi-du 1 ke--[ ]-za-[ inf. mut." : "% ğ€‚%ğ€ %ğ€º ğ€€% % ğ€·ğ€‰ğ€™ %%%% %ğ€µ ğ€% % %ğ€­ğ€ğ€ªğ€ % % ğ€‚ğ€ ğ€‚ğ€ %ğ€ƒ%ğ€  ğ€‡ğ€¿ ğ€ ğ€”ğ€™ğ€« ğ€¿ğ€¹ğ€ 1 ğ€€ğ€¶ğ€¦ğ€³ğ€¨ğ€µ 1% ğ€‚ğ€ ğ€ƒğ€  ğ€ªğ€¿ ğ€ ğ€”ğ€™ğ€« ğ€ ğ€«ğ€‚ğ€² 1 ğ€ƒğ€  ğ€ğ€ ğ€‡ğ€·ğ€ 1 %ğ€  ğ€ƒğ€™ğ€®ğ€„ 1 ğ€ª% %ğ€¹ğ€‰ 1 ğ€% %ğ€¼%" # https://liber.cnr.it/tablet/view/697

# Test LB.R.53
# Scenario: Test that checkmarks (i.e. 'X') are not printed in regularized scenarios.
# Requirements mapping:
    # LB.69: Tokenise each instance of 'X'. Represent this text as is in the annotated output, but do not include in the regularized output.

    "fragmentum A sup. mut. ] X MUL 1 ]--u-ra MUL 1 X ]-na MUL 1 tu-ka-na X MUL 1 ]-ma MUL 1 te-qa-ja MUL 1 ]-ja MUL 1-[ ]-ja-mu-ta MUL 1-[ ]--ta2-no-[ inf. mut." : "% ğ‚ 1 %ğ€„ğ€¨ ğ‚ 1 %ğ€™ ğ‚ 1 ğ€¶ğ€ğ€™ ğ‚ 1 %ğ€” ğ‚ 1 ğ€³ğ€£ğ€Š ğ‚ 1 %ğ€Š ğ‚ 1% %ğ€Šğ€˜ğ€² ğ‚ 1% %ğ‹ğ€œ%"

# Test LB.R.54
# Scenario: Test that '|' is not printed in regularized scenarios.
# Requirements mapping:
    # LB.70: Tokenise each instance of '|'. Represent this sign as is in the annotated output, but do not include in the regularized output.

    "Î± ]a3-wo-re-u-|si|-si Î² do-ke Î³ [â€¢]-ja-wo-ne" : "%ğğ€ºğ€©ğ€„ğ€¯ğ€¯ ğ€ˆğ€ %ğ€Šğ€ºğ€š"

# Test LB.R.55
# Scenario: Test that both '<em>' and '</em>' are not printed in either annotated or regularized scenarios.
# Requirements mapping:
    # LB.71: Ignore each instance of '<em>'. Do not represent this string in either the annotated or the regularized output.
    # LB.72: Ignore each instance of '</em>'. Do not represent this string in either the annotated or the regularized output.

    "fragmentum A fragmentum B sup. mut. sup. mut.</em> ]--to-[ ]-da-*22-to HORD [ ] 'da-*22-to' HORD 2 da-]-*22-to HORD-[ ]--ro 'da-*22-to' HORD 2 inf. mut. ]--ri 'da-*22-to' HORD 2 ] vac. inf. mut." : "%ğ€µ% %ğ€…ğ’ğ€µ ğ‚ % % ğ€…ğ’ğ€µ ğ‚ 2 ğ€…%ğ’ğ€µ ğ‚% %ğ€« ğ€…ğ’ğ€µ ğ‚ 2 %ğ€ª ğ€…ğ’ğ€µ ğ‚ 2 %"

# SPACE tests

# Test LB.R.56
# Scenario: Test that the space is removed after the '+' sign, and the correct sign is printed in the regularized scenario.
# Requirements mapping:
    # LB.1-b: If a blank space appears before/after '+', then remove both those spaces in both the annotated and regularized outputs.
    
    "]r\u0323o\u0323 , / da-mo GRA [ ]8 OLIV+ A 12" : "%ğ€« ğ€…ğ€— ğ‚ % %8 ğ‚+ğ€€ 12"

# TELA tests

# Test LB.R.57
# Scenario: Test that spaces are removed after 'TELA' and before either a '1', '2', '3', '4' or 'x', and the correct sign/s are printed in regularized scenarios.
# Requirements mapping:
    # LB.1-d: If a blank space appears after 'TELA' and before either a '1', '2', '3', '4' or 'x', then remove that space in both the annotated and regularized outputs.
    
    "]\u0323a\u0323-ra-ka-te-ja / tu-na-no TELA 1\u0323 1 [" : "%ğ€€ğ€¨ğ€ğ€³ğ€Š ğ€¶ğ€™ğ€œ ğ‚§Â¹ 1 %"
    "] * 161 TELA 2 [" : "% ğ‚© ğ‚§Â² %"
    "nu-wa-i-ja , / 'pa-we-a' * 161 TELA 3 30\u27e6 \u27e7" : "ğ€ğ€·ğ€‚ğ€Š ğ€ğ€¸ğ€€ ğ‚© ğ‚§Â³ 30"
    "] TELA 4 + PU 1[" : "% ğ‚§â´+ğ€¢ 1%"
    "]ti-jo\u2e24 \u2e25 / to-mi-ka TELA x 30" : "%ğ€´ğ€ ğ€µğ€–ğ€ ğ‚§Ë£ 30"
    ']TELA 10 âŸ¦        âŸ§ *158 1' : '%ğ‚§ 10 ğ‚¦ 1'
    "to-sa TELA 40 o TELA 1 6[" : "ğ€µğ€­ ğ‚§ 40 ğ€ƒ ğ‚§Â¹ 6%"
    
# FRINGE SCENARIOS

# Test LB.U.58
# Scenario: Test that the seal impression annotation 'CMS VS1B 049' is not printed in regularized scenarios.
# Requirements mapping
    # Handled as an individual fringe case in code, no specific requirement.

    "Î± A supra sigillum CMS VS1B 049 Î² a-pe-we-de" : "ğ€€ ğ€€ğ€Ÿğ€¸ğ€†"

# Test LB.U.59
# Scenario: Check that the mappings for 'exception scenarios' are working as expected for regularized scenarios.
# Requirements mapping:
    # Handled as individual fringe cases via mapping, no specific requirements.

    "sup. mut. ?OVIS]-:m [" : "ğ‚‡ %"
    "]-si 1 tu 1 ki-zo 1 MUL 3 TELA-[;1+TE ]-a-ma-no--[ ]-1 o-ri-mo MUL 3 TELA;1+TE 1 pu-zo , ti-no , pi-ja-mu-nu MUL-[ ]-ni-ta , o-sa-po-to MUL 3 TELA-[;1]-+TE 1 [ ] vac. [" : "%ğ€¯ 1 ğ€¶ 1 ğ€‘ğ€¿ 1 ğ‚ 3 ğ‚§Â¹%+ğ€³ %ğ€€ğ€”ğ€œ% %1 ğ€ƒğ€ªğ€— ğ‚ 3 ğ‚§Â¹+ğ€³ 1 ğ€¢ğ€¿ ğ€´ğ€œ ğ€ ğ€Šğ€˜ğ€ ğ‚% %ğ€›ğ€² ğ€ƒğ€­ğ€¡ğ€µ ğ‚ 3 ğ‚§Â¹%+ğ€³ 1 % % %"

# Test LB.R.60
# Scenario: Check that special mapping for 'MEÂ±RI' with interrupting angle brackets, i.e. 'ME<Â±RI>', is working as expected for regularized scenarios.
# Requirements mapping:
    # Handled as individual fringe cases via mapping, no specific requirements.
    # Check with Kabir how this has been handled in code.
    
    "]-o-pe-ro *209VAS 'ME<Â±RI>' 5 [" : "%ğ€ƒğ€Ÿğ€« ğƒ¨ ğ‚™ 5 %" # https://liber.cnr.it/tablet/view/4215?wl=23278
    "]-i-to , / da-nwa MEÂ±RI *209VAS+A 16 *172 8" : "%ğ€‚ğ€µ ğ€…ğ… ğ‚™ ğƒ¨+ğ€€ 16 ğ‚´ 8" # regression test for regular 'MEÂ±RI'

# NEW SCENARIO
# Test LB.R.61
    # NEW REQUIREMENT: Tokenise each instance of 'sin.'. Represent this text as is in the annotated output, but do not include in the regularized output.
    
    "ku-ro-ro2 AROM 13 T 5 KAÂ±PO 4 *157 28 LANA 5 me-po 6 S 1 V 4 ko-ri-jo-da-na AROM 21 i-re-we[ ] T 2 v. ta-we-si-jo-jo , ke-ro-si-ja VIR 20[ a-pi-qo-o , ke-ro-si-ja VIR 17 [ a-pi-o-to , ke-ro-si-ja VIR 18 o-to-wo-o , ke-ro-si-ja VIR 13 lat. sin. ka-ma-e-we VIR 10" : "ğ€“ğ€«ğŠ ğ‚‘ 13 ğ„¼ 5 ğ‚“ 4 ğ‚¥ 28 ğ‚ 5 ğ€•ğ€¡ 6 ğ„½ 1 ğ„¾ 4 ğ€’ğ€ªğ€ğ€…ğ€™ ğ‚‘ 21 ğ€‚ğ€©ğ€¸% % ğ„¼ 2 ğ€²ğ€¸ğ€¯ğ€ğ€ ğ€ğ€«ğ€¯ğ€Š ğ‚€ 20% ğ€€ğ€ ğ€¦ğ€ƒ ğ€ğ€«ğ€¯ğ€Š ğ‚€ 17 % ğ€€ğ€ ğ€ƒğ€µ ğ€ğ€«ğ€¯ğ€Š ğ‚€ 18 ğ€ƒğ€µğ€ºğ€ƒ ğ€ğ€«ğ€¯ğ€Š ğ‚€ 13 ğ€ğ€”ğ€ğ€¸ ğ‚€ 10"